{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Machine Learning\n",
    "\n",
    "This is an older Kaggle Competition with an objective of providing a classic dataset to predict the survival of passengers on the Titanic. We have Train Dataset and Test Dataset for rus to apply our Machine Learning Models on.\n",
    "\n",
    "* Here I would be applying several models on the same dataset in order to check and compare the different models\n",
    "    1. Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing the datasets\n",
    "train_data=pd.read_csv(\"train.csv\")\n",
    "test_data=pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the imported data to verify if the import was successful\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running some Data Exploration to understand and visualize the data\n",
    "\n",
    "#### Bar Graphs to understand the Predictor Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~atheros167/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~atheros167/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived_count=train_data.groupby([\"Survived\"], as_index=False)[\"PassengerId\"].count()\n",
    "import plotly \n",
    "plotly.tools.set_credentials_file(username='atheros167', api_key='t6wQEzT7YVZUIy97HAka')\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "data = [go.Bar(\n",
    "            x=survived_count[\"Survived\"],\n",
    "            y=survived_count[\"PassengerId\"]\n",
    "    )]\n",
    "\n",
    "py.iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~atheros167/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Pie Charts for number of Missing Data\n",
    "\n",
    "missing_count={}\n",
    "missing_count[\"Missing\"]=train_data.shape[0] - train_data.dropna().shape[0]\n",
    "missing_count[\"Not_Missing\"]=train_data.dropna().shape[0]\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "labels = list(missing_count.keys())\n",
    "values = list(missing_count.values())\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "\n",
    "py.iplot([trace], filename='basic_pie_chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chart above we notice that majority of the rows (~80%) have some record missing. SO lets lets explore the data to see which columns have missing records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the missing data comes from the Cabin field, which luckily for us is not a very essential column towards predicting our survival column. We can ignore this column since we will be dropping this column from our analysis.\n",
    "\n",
    "Age columns however is intuitively an important column towards predicting survival. So we will be doing some manipulation to the data to fill the missing rows\n",
    "\n",
    "The final columns with missing records is the Embarked column with 2 records missing. For the sake of convenience we will be dropping these two records as well, since it should not affect the model much by doing so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survived column vs Gender column Stacked Bar Graph\n",
    "\n",
    "Age and Gender are other few columns that intuitively makes sense to possible affect the outcome for Survival. So lets take a deeper look to understand these two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived_0</th>\n",
       "      <th>Survived_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>81</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>468</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived_0  Survived_1\n",
       "0  female          81         233\n",
       "1    male         468         109"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_count=train_data.groupby([\"Sex\",\"Survived\"], as_index=False)[\"PassengerId\"].count()\n",
    "gender_count2=gender_count.pivot(index='Sex',columns='Survived', values='PassengerId').reset_index('Sex')\n",
    "gender_count2.columns=['Sex','Survived_0','Survived_1']\n",
    "gender_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~atheros167/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=gender_count2[\"Sex\"],\n",
    "    y=gender_count2[\"Survived_0\"],\n",
    "    name='Didnt_Survive'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=gender_count2[\"Sex\"],\n",
    "    y=gender_count2[\"Survived_1\"],\n",
    "    name='Survived'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Missing Data - Replacement\n",
    "\n",
    "There are a number of missing records for Age which intuitively makes a good predictor for the survival. So exploring ways to replace the data.\n",
    "* We would be parsing a string from the name like \"master\" or \"mr\" or \"miss\" to use that as a segmentation and replacing the missing age for a record with the mean age of those groups.\n",
    "    - For example: If we have a missing record with Passenger name with \"Master\" or \"master\" in the name then we replace with the average age of the \"Master\" passengers\n",
    "* If there are still records that cannot be replaced, then we will replace them with the mean age for the group of combination Pclass and Sex.\n",
    "    - For example if we are not able to replace the age for a record using the method 1, then for the missing record of Pclass 1 and Sex=\"Female\", we will insert the value for the mean age of the passengers who travelled in the same Pclass and were females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['Master.', 3.988571428571429],\n",
       " 1: ['Miss.', 27.738636363636363],\n",
       " 2: ['Mr.', 40.712765957446805],\n",
       " 3: ['Mrs.', 38.23684210526316]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list consisting of possible titles\n",
    "title_list=[\"Mr.\",\"mr.\",\"Mrs.\",\"mrs.\",\"Miss.\",\"miss.\",\"Ms.\",\"ms.\",\"Master.\",\"master.\"]\n",
    "\n",
    "# defining a function to get the index for the elements in the title\n",
    "def title_create(arg):\n",
    "    for i in title_list:\n",
    "        train_data[i]=arg.str.find(i)\n",
    "\n",
    "# Defining a function to remove the created columns after associating hte correct salutation\n",
    "def remove_columns(arg):\n",
    "    for i in arg:\n",
    "        del train_data[i]\n",
    "\n",
    "title_create(train_data['Name'])\n",
    "train_data['final_salutation']=train_data[[\"Mr.\",\"mr.\",\"Mrs.\",\"mrs.\",\"Miss.\",\"miss.\",\"Ms.\",\"ms.\",\"Master.\",\"master.\"]].idxmax(axis=1)\n",
    "\n",
    "remove_columns(title_list)\n",
    "\n",
    "# these are the average values by the salutations.\n",
    "# Checking if they make sense\n",
    "\n",
    "age_mean=(train_data.dropna().groupby([\"final_salutation\"], as_index=False)[\"Age\"].mean()).T.to_dict('List')\n",
    "age_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the above make sense, lets replace the missing Age rows with above numbers\n",
    "train_data[\"Age\"] = train_data.groupby(\"final_salutation\").transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId         891\n",
       "Survived            891\n",
       "Pclass              891\n",
       "Name                891\n",
       "Sex                 891\n",
       "Age                 891\n",
       "SibSp               891\n",
       "Parch               891\n",
       "Ticket              891\n",
       "Fare                891\n",
       "Cabin               204\n",
       "Embarked            889\n",
       "final_salutation    891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets relook at the data to confirm all the records for the column Age look good now\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dropping columns that wont be useful in our models\n",
    "\n",
    "* Now that all our columns are ready, we can drop a few non useful columns like Name, final_salutation, Cabin & Ticket\n",
    "* Also we can drop the two records withmissing embarked.\n",
    "* Convert the Sex and Embarked columns in to dummy variables to make them numerical categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Age  SibSp  Parch     Fare Embarked  Gender\n",
       "0            1         0       3  1.0      1      0   7.2500        S       1\n",
       "1            2         1       1  2.0      1      0  71.2833        C       0\n",
       "2            3         1       3  3.0      0      0   7.9250        S       0\n",
       "3            4         1       1  4.0      1      0  53.1000        S       0\n",
       "4            5         0       3  5.0      0      0   8.0500        S       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data['Name']\n",
    "del train_data['final_salutation']\n",
    "del train_data['Cabin']\n",
    "del train_data['Ticket']\n",
    "\n",
    "# The function \"f\" here is to convert the column Sex into dummy variables 1 or 0 since we can input these variables \n",
    "# into our model\n",
    "# We can use One Hot Encoder here, but since the dataset is small and simple we can use this to understand what is happenning\n",
    "def f(row):\n",
    "    if row['Sex'] == 'male':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "train_data['Gender'] = train_data.apply(f, axis=1)\n",
    "# Now that we have created a column called Gender we can drop the Sex column off\n",
    "del train_data['Sex']\n",
    "\n",
    "\n",
    "# Lets take a look at how our data looks like now\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still have to drop the two records with Embarked column having \"NAN\" records and need to substitute the String values for numerical for the Embarked column before we can run our first model Logistic Regression on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embarked_replace(row):\n",
    "    if row['Embarked']=='S':\n",
    "        val=1\n",
    "    elif row['Embarked']=='C':\n",
    "        val=2\n",
    "    elif row['Embarked']=='Q':\n",
    "        val=3\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "# As before, we are applying the function on our Embark column to make the column numerical.\n",
    "# Then we delete the column\n",
    "# Finally we drop the records where the column contained \"NAN\"\n",
    "train_data['Embark_new']=train_data.apply(embarked_replace,axis=1)\n",
    "del train_data['Embarked']\n",
    "\n",
    "# Creating our final dataset that can be fed into various models\n",
    "\n",
    "train_data=train_data[train_data.Embark_new != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Look at the data before it we can start building different models off of the data called ==> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Embark_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Age  SibSp  Parch     Fare  Gender  \\\n",
       "0            1         0       3  1.0      1      0   7.2500       1   \n",
       "1            2         1       1  2.0      1      0  71.2833       0   \n",
       "2            3         1       3  3.0      0      0   7.9250       0   \n",
       "3            4         1       1  4.0      1      0  53.1000       0   \n",
       "4            5         0       3  5.0      0      0   8.0500       1   \n",
       "\n",
       "   Embark_new  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    889\n",
       "Survived       889\n",
       "Pclass         889\n",
       "Age            889\n",
       "SibSp          889\n",
       "Parch          889\n",
       "Fare           889\n",
       "Gender         889\n",
       "Embark_new     889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything Looks Set for our first Model. Lets build some models now!!!\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Logistic Regression is a classification technique which uses a bunch of independent varaible to predict a probabililty of occurance for a categorical dependent variable. It uses a sigmoid function to predict the probability of dependent variable to be between 0 and 1 using a y=1/(1+e^(-x)) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pylab import scatter, show, legend, xlabel, ylabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the X label and Y Label for our Models\n",
    "* We need to convert the X and Y variables into a Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=train_data[[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Gender\",\"Embark_new\"]]\n",
    "X=np.array(X)\n",
    "Y=train_data[[\"Survived\"]]\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into Train and Test.\n",
    "* Using 30% of the data as Test Data \n",
    "* Remaining 70% is our Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rames\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797752808989\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_test, predicted)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141,  18],\n",
       "       [ 36,  72]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, predicted,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the test dataset along the same lines as train and apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1235</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mrs. James Warburton Martinez (Charlo...</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Ethel Flora</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mrs. Mark (Mary McDougald)</td>\n",
       "      <td>female</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Mrs. Arthur Larned (Emily Maria Borie)</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>951</td>\n",
       "      <td>1</td>\n",
       "      <td>Chaudanson, Miss. Victorine</td>\n",
       "      <td>female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B61</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0         1235       1  Cardeza, Mrs. James Warburton Martinez (Charlo...   \n",
       "1          945       1                         Fortune, Miss. Ethel Flora   \n",
       "2          961       1                Fortune, Mrs. Mark (Mary McDougald)   \n",
       "3          916       1    Ryerson, Mrs. Arthur Larned (Emily Maria Borie)   \n",
       "4          951       1                        Chaudanson, Miss. Victorine   \n",
       "\n",
       "      Sex   Age  SibSp  Parch    Ticket      Fare            Cabin Embarked  \n",
       "0  female  58.0      0      1  PC 17755  512.3292      B51 B53 B55        C  \n",
       "1  female  28.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "2  female  60.0      1      4     19950  263.0000      C23 C25 C27        S  \n",
       "3  female  48.0      1      3  PC 17608  262.3750  B57 B59 B63 B66        C  \n",
       "4  female  36.0      0      0  PC 17608  262.3750              B61        C  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data['Cabin']\n",
    "del test_data['Ticket']\n",
    "del test_data['PassengerId']\n",
    "\n",
    "# Creating a list of salutations based on reading the name string\n",
    "def title_create(arg):\n",
    "    for i in title_list:\n",
    "        test_data[i]=arg.str.find(i)\n",
    "\n",
    "title_create(test_data['Name'])\n",
    "\n",
    "# From the above creating a column to pick the max value under the columns\n",
    "test_data['final_salutation']=test_data[[\"Mr.\",\"mr.\",\"Mrs.\",\"mrs.\",\"Miss.\",\"miss.\",\"Ms.\",\"ms.\",\"Master.\",\"master.\"]].idxmax(axis=1)\n",
    "\n",
    "# For the records with missing Age, we are applying the average age based on the salutations.\n",
    "\n",
    "test_data[\"Age\"] = test_data.groupby(\"final_salutation\").transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Now we do not need those columns anymore\n",
    "def remove_columns(arg):\n",
    "    for i in arg:\n",
    "        del test_data[i]\n",
    "\n",
    "remove_columns(title_list)\n",
    "\n",
    "del test_data['Name']\n",
    "del test_data['final_salutation']\n",
    "\n",
    "\n",
    "#The function \"f\" here is to convert the column Sex into dummy variables 1 or 0 since we can input these variables into our model\n",
    "#We can use One Hot Encoder here, but since the dataset is small and simple we can use this to understand what is happenning\n",
    "\n",
    "def f(row):\n",
    "    if row['Sex'] == 'male':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "test_data['Gender'] = test_data.apply(f, axis=1)\n",
    "# Now that we have created a column called Gender we can drop the Sex column off\n",
    "del test_data['Sex']\n",
    "\n",
    "test_data['Embark_new']=test_data.apply(embarked_replace,axis=1)\n",
    "del test_data['Embarked']\n",
    "\n",
    "# There are a few rows with Fare Information missing. FOr these records, we take the average fare per Pclass and Age\n",
    "\n",
    "test_data[\"Fare\"] = test_data.groupby([\"Pclass\",\"Age\"]).transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "#Creating our final dataset that can be fed into various models\n",
    "\n",
    "X_test_final=test_data[[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Gender\",\"Embark_new\"]]\n",
    "X_test_final=np.array(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the test data to predict the values for the Survived column in the test dataset\n",
    "predicted_final=clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exporting the data into a csv\n",
    "\n",
    "test_data=pd.read_csv(\"test.csv\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": predicted_final\n",
    "    })\n",
    "submission.to_csv('titanic_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier\n",
    "\n",
    "Now that we have applied the Logistic Regression Model, we can try some other models to see how they fare against the logistic models. One of the simple models to apply is a SVM Classifier model which basically tries to draw a line at the threshold of the classification (here 1) and tries to predict which side of the line would the observation be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rames\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,Y_train) \n",
    "predict_svr=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588014981273\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_test, predict_svr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153,   6],\n",
       "       [104,   4]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, predict_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_final_svr=clf.predict(X_test_final)\n",
    "test_data=pd.read_csv(\"test.csv\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": predicted_final_svr\n",
    "    })\n",
    "submission.to_csv('titanic_output_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the Logistic Regression model out performed the SVM model here. Next lets try an Artificial Neural Network\n",
    "\n",
    "## Artificial Neural Network\n",
    "\n",
    "Artificial Neural Network is a model that tries to create input nodes using the input variables and with the help of a few hidden layers tries to back propagates a correction to the weights of the input variables in order to make the output more closer to the true values. In theory, this should be more accurate that our earlier models.\n",
    "Lets check it out if that true :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardizing the input variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the keras libraries to create out Neural Networks\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the initial object as a sequential model with more than one layers\n",
    "clf=Sequential()\n",
    "\n",
    "# Adding the first hidden layer\n",
    "# output_dim is the average of input dims=7 and output dims=1.\n",
    "# init is the function to initialize the weights. uniform is the most simple way to add a close to 0 value for weights \n",
    "# Choosing the activation function to be relu which corresponds to rectifier function \n",
    "clf.add(Dense(units=4,kernel_initializer=\"uniform\",activation='relu',input_dim=7))\n",
    "\n",
    "#Adding the second hidden layer\n",
    "clf.add(Dense(units=4,kernel_initializer=\"uniform\",activation='relu'))\n",
    "\n",
    "# Adding the final output layer\n",
    "clf.add(Dense(units=1,kernel_initializer=\"uniform\",activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling using the ADAM optimizer for Stachastic Gradient Descent\n",
    "clf.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "622/622 [==============================] - 0s - loss: 0.6900 - acc: 0.6286     \n",
      "Epoch 2/100\n",
      "622/622 [==============================] - 0s - loss: 0.6820 - acc: 0.6270     \n",
      "Epoch 3/100\n",
      "622/622 [==============================] - 0s - loss: 0.6644 - acc: 0.6270     \n",
      "Epoch 4/100\n",
      "622/622 [==============================] - 0s - loss: 0.6310 - acc: 0.7042     \n",
      "Epoch 5/100\n",
      "622/622 [==============================] - 0s - loss: 0.5859 - acc: 0.7894     \n",
      "Epoch 6/100\n",
      "622/622 [==============================] - 0s - loss: 0.5412 - acc: 0.8006     \n",
      "Epoch 7/100\n",
      "622/622 [==============================] - 0s - loss: 0.5058 - acc: 0.8087     \n",
      "Epoch 8/100\n",
      "622/622 [==============================] - 0s - loss: 0.4816 - acc: 0.8055     \n",
      "Epoch 9/100\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.4704 - acc: 0.807 - 0s - loss: 0.4666 - acc: 0.8071     \n",
      "Epoch 10/100\n",
      "622/622 [==============================] - 0s - loss: 0.4572 - acc: 0.8071     \n",
      "Epoch 11/100\n",
      "622/622 [==============================] - 0s - loss: 0.4509 - acc: 0.8071     \n",
      "Epoch 12/100\n",
      "622/622 [==============================] - 0s - loss: 0.4469 - acc: 0.8071     \n",
      "Epoch 13/100\n",
      "622/622 [==============================] - 0s - loss: 0.4439 - acc: 0.8071     \n",
      "Epoch 14/100\n",
      "622/622 [==============================] - 0s - loss: 0.4412 - acc: 0.8071     \n",
      "Epoch 15/100\n",
      "622/622 [==============================] - 0s - loss: 0.4387 - acc: 0.8039     \n",
      "Epoch 16/100\n",
      "622/622 [==============================] - 0s - loss: 0.4365 - acc: 0.8071     \n",
      "Epoch 17/100\n",
      "622/622 [==============================] - 0s - loss: 0.4356 - acc: 0.8103     \n",
      "Epoch 18/100\n",
      "622/622 [==============================] - 0s - loss: 0.4331 - acc: 0.8103     \n",
      "Epoch 19/100\n",
      "622/622 [==============================] - 0s - loss: 0.4321 - acc: 0.8071     \n",
      "Epoch 20/100\n",
      "622/622 [==============================] - 0s - loss: 0.4311 - acc: 0.8055     \n",
      "Epoch 21/100\n",
      "622/622 [==============================] - 0s - loss: 0.4295 - acc: 0.8055     \n",
      "Epoch 22/100\n",
      "622/622 [==============================] - 0s - loss: 0.4286 - acc: 0.8071     \n",
      "Epoch 23/100\n",
      "622/622 [==============================] - 0s - loss: 0.4276 - acc: 0.8055     \n",
      "Epoch 24/100\n",
      "622/622 [==============================] - 0s - loss: 0.4269 - acc: 0.8071     \n",
      "Epoch 25/100\n",
      "622/622 [==============================] - 0s - loss: 0.4258 - acc: 0.8071     \n",
      "Epoch 26/100\n",
      "622/622 [==============================] - 0s - loss: 0.4249 - acc: 0.8071     \n",
      "Epoch 27/100\n",
      "622/622 [==============================] - 0s - loss: 0.4243 - acc: 0.8055     \n",
      "Epoch 28/100\n",
      "622/622 [==============================] - 0s - loss: 0.4233 - acc: 0.8055     \n",
      "Epoch 29/100\n",
      "622/622 [==============================] - 0s - loss: 0.4226 - acc: 0.8055     \n",
      "Epoch 30/100\n",
      "622/622 [==============================] - 0s - loss: 0.4223 - acc: 0.8087     \n",
      "Epoch 31/100\n",
      "622/622 [==============================] - 0s - loss: 0.4216 - acc: 0.8055     \n",
      "Epoch 32/100\n",
      "622/622 [==============================] - 0s - loss: 0.4209 - acc: 0.8071     \n",
      "Epoch 33/100\n",
      "622/622 [==============================] - 0s - loss: 0.4200 - acc: 0.8103     \n",
      "Epoch 34/100\n",
      "622/622 [==============================] - 0s - loss: 0.4199 - acc: 0.8119     \n",
      "Epoch 35/100\n",
      "622/622 [==============================] - 0s - loss: 0.4192 - acc: 0.8071     \n",
      "Epoch 36/100\n",
      "622/622 [==============================] - 0s - loss: 0.4194 - acc: 0.8023     \n",
      "Epoch 37/100\n",
      "622/622 [==============================] - 0s - loss: 0.4184 - acc: 0.8119     \n",
      "Epoch 38/100\n",
      "622/622 [==============================] - ETA: 0s - loss: 0.4071 - acc: 0.820 - 0s - loss: 0.4179 - acc: 0.8119     \n",
      "Epoch 39/100\n",
      "622/622 [==============================] - 0s - loss: 0.4177 - acc: 0.8135     \n",
      "Epoch 40/100\n",
      "622/622 [==============================] - 0s - loss: 0.4173 - acc: 0.8071     \n",
      "Epoch 41/100\n",
      "622/622 [==============================] - 0s - loss: 0.4172 - acc: 0.8135     \n",
      "Epoch 42/100\n",
      "622/622 [==============================] - 0s - loss: 0.4167 - acc: 0.8135     \n",
      "Epoch 43/100\n",
      "622/622 [==============================] - 0s - loss: 0.4169 - acc: 0.8119     \n",
      "Epoch 44/100\n",
      "622/622 [==============================] - 0s - loss: 0.4166 - acc: 0.8087     \n",
      "Epoch 45/100\n",
      "622/622 [==============================] - 0s - loss: 0.4163 - acc: 0.8135     \n",
      "Epoch 46/100\n",
      "622/622 [==============================] - 0s - loss: 0.4158 - acc: 0.8135     \n",
      "Epoch 47/100\n",
      "622/622 [==============================] - 0s - loss: 0.4155 - acc: 0.8135     \n",
      "Epoch 48/100\n",
      "622/622 [==============================] - 0s - loss: 0.4153 - acc: 0.8119     \n",
      "Epoch 49/100\n",
      "622/622 [==============================] - 0s - loss: 0.4157 - acc: 0.8151     \n",
      "Epoch 50/100\n",
      "622/622 [==============================] - 0s - loss: 0.4150 - acc: 0.8103     \n",
      "Epoch 51/100\n",
      "622/622 [==============================] - 0s - loss: 0.4151 - acc: 0.8183     \n",
      "Epoch 52/100\n",
      "622/622 [==============================] - 0s - loss: 0.4157 - acc: 0.8167     \n",
      "Epoch 53/100\n",
      "622/622 [==============================] - 0s - loss: 0.4146 - acc: 0.8151     \n",
      "Epoch 54/100\n",
      "622/622 [==============================] - 0s - loss: 0.4143 - acc: 0.8135     \n",
      "Epoch 55/100\n",
      "622/622 [==============================] - 0s - loss: 0.4146 - acc: 0.8135     \n",
      "Epoch 56/100\n",
      "622/622 [==============================] - 0s - loss: 0.4139 - acc: 0.8135     \n",
      "Epoch 57/100\n",
      "622/622 [==============================] - 0s - loss: 0.4146 - acc: 0.8199     \n",
      "Epoch 58/100\n",
      "622/622 [==============================] - 0s - loss: 0.4136 - acc: 0.8135     \n",
      "Epoch 59/100\n",
      "622/622 [==============================] - 0s - loss: 0.4135 - acc: 0.8151     \n",
      "Epoch 60/100\n",
      "622/622 [==============================] - 0s - loss: 0.4141 - acc: 0.8167     \n",
      "Epoch 61/100\n",
      "622/622 [==============================] - 0s - loss: 0.4139 - acc: 0.8183     \n",
      "Epoch 62/100\n",
      "622/622 [==============================] - 0s - loss: 0.4135 - acc: 0.8151     \n",
      "Epoch 63/100\n",
      "622/622 [==============================] - 0s - loss: 0.4135 - acc: 0.8135     \n",
      "Epoch 64/100\n",
      "622/622 [==============================] - 0s - loss: 0.4130 - acc: 0.8135     \n",
      "Epoch 65/100\n",
      "622/622 [==============================] - 0s - loss: 0.4129 - acc: 0.8151     \n",
      "Epoch 66/100\n",
      "622/622 [==============================] - 0s - loss: 0.4126 - acc: 0.8119     \n",
      "Epoch 67/100\n",
      "622/622 [==============================] - 0s - loss: 0.4133 - acc: 0.8167     \n",
      "Epoch 68/100\n",
      "622/622 [==============================] - 0s - loss: 0.4123 - acc: 0.8151     \n",
      "Epoch 69/100\n",
      "622/622 [==============================] - 0s - loss: 0.4128 - acc: 0.8183     \n",
      "Epoch 70/100\n",
      "622/622 [==============================] - 0s - loss: 0.4123 - acc: 0.8151     \n",
      "Epoch 71/100\n",
      "622/622 [==============================] - 0s - loss: 0.4125 - acc: 0.8151     \n",
      "Epoch 72/100\n",
      "622/622 [==============================] - 0s - loss: 0.4122 - acc: 0.8151     \n",
      "Epoch 73/100\n",
      "622/622 [==============================] - 0s - loss: 0.4121 - acc: 0.8167     \n",
      "Epoch 74/100\n",
      "622/622 [==============================] - 0s - loss: 0.4122 - acc: 0.8151     \n",
      "Epoch 75/100\n",
      "622/622 [==============================] - 0s - loss: 0.4122 - acc: 0.8087     \n",
      "Epoch 76/100\n",
      "622/622 [==============================] - 0s - loss: 0.4118 - acc: 0.8135     \n",
      "Epoch 77/100\n",
      "622/622 [==============================] - 0s - loss: 0.4117 - acc: 0.8135     \n",
      "Epoch 78/100\n",
      "622/622 [==============================] - 0s - loss: 0.4118 - acc: 0.8119     \n",
      "Epoch 79/100\n",
      "622/622 [==============================] - 0s - loss: 0.4115 - acc: 0.8135     \n",
      "Epoch 80/100\n",
      "622/622 [==============================] - 0s - loss: 0.4118 - acc: 0.8135     \n",
      "Epoch 81/100\n",
      "622/622 [==============================] - 0s - loss: 0.4114 - acc: 0.8103     \n",
      "Epoch 82/100\n",
      "622/622 [==============================] - 0s - loss: 0.4116 - acc: 0.8167     \n",
      "Epoch 83/100\n",
      "622/622 [==============================] - 0s - loss: 0.4114 - acc: 0.8103     \n",
      "Epoch 84/100\n",
      "622/622 [==============================] - 0s - loss: 0.4118 - acc: 0.8087     \n",
      "Epoch 85/100\n",
      "622/622 [==============================] - 0s - loss: 0.4110 - acc: 0.8167     \n",
      "Epoch 86/100\n",
      "622/622 [==============================] - 0s - loss: 0.4110 - acc: 0.8103     \n",
      "Epoch 87/100\n",
      "622/622 [==============================] - 0s - loss: 0.4107 - acc: 0.8087     \n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 0s - loss: 0.4107 - acc: 0.8151     \n",
      "Epoch 89/100\n",
      "622/622 [==============================] - 0s - loss: 0.4107 - acc: 0.8183     \n",
      "Epoch 90/100\n",
      "622/622 [==============================] - 0s - loss: 0.4111 - acc: 0.8135     \n",
      "Epoch 91/100\n",
      "622/622 [==============================] - 0s - loss: 0.4103 - acc: 0.8151     \n",
      "Epoch 92/100\n",
      "622/622 [==============================] - 0s - loss: 0.4103 - acc: 0.8135     \n",
      "Epoch 93/100\n",
      "622/622 [==============================] - 0s - loss: 0.4109 - acc: 0.8119     \n",
      "Epoch 94/100\n",
      "622/622 [==============================] - 0s - loss: 0.4103 - acc: 0.8135     \n",
      "Epoch 95/100\n",
      "622/622 [==============================] - 0s - loss: 0.4101 - acc: 0.8119     \n",
      "Epoch 96/100\n",
      "622/622 [==============================] - 0s - loss: 0.4102 - acc: 0.8135     \n",
      "Epoch 97/100\n",
      "622/622 [==============================] - 0s - loss: 0.4098 - acc: 0.8167     \n",
      "Epoch 98/100\n",
      "622/622 [==============================] - 0s - loss: 0.4104 - acc: 0.8135     \n",
      "Epoch 99/100\n",
      "622/622 [==============================] - 0s - loss: 0.4105 - acc: 0.8151     \n",
      "Epoch 100/100\n",
      "622/622 [==============================] - 0s - loss: 0.4102 - acc: 0.8167     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb11b89ba8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets fit this for 100 epochs and a batch_size of 10\n",
    "clf.fit(X_train,Y_train,batch_size=10,epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150,   9],\n",
       "       [ 46,  62]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the model on the split test data\n",
    "Y_pred=clf.predict(X_test)\n",
    "Y_pred=(Y_pred>0.5)\n",
    "\n",
    "# Calculating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test,Y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training dataset we get an average accuracy of 81%. From Test dataset we get 79.4 %, which is pretty much a good alignment to conclude that there is not much over fitting.\n",
    "So, like we expected we are getting a slightly better result using the ANN as compared to Logistic Regression or SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
